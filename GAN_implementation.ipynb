{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The following code was taken by the repository of Harry Stuart. https://github.com/harrystuart/tfworldhackathon.\n",
        "\n",
        "This is an implementation of WaveGAN architecture to generate audio files of 4 seconds. In order to  generate audio for 10 genres, this scrit is supposed to be run 10 times, replacing the value of variable \"INSTRUMENT\" for respective  genre."
      ],
      "metadata": {
        "id": "ZlM2H9GommGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import modules\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Lambda, Dense, LSTM, Activation, Input, Bidirectional, Dropout\n",
        "from tensorflow.keras.layers import Reshape, Conv2DTranspose, TimeDistributed, Conv1D, LeakyReLU, Layer, ReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "import numpy as np\n",
        "import librosa\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import soundfile as sf\n",
        "\n"
      ],
      "metadata": {
        "id": "uHVgu2NxZ6Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pELKACyFpMrP",
        "outputId": "59655f19-d39d-497a-b55d-d4b6d99659e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the Generator of GAN\n",
        "def Generator(d, num_samples, c=16):\n",
        "\n",
        "    input_layer = Input(shape=(100,))\n",
        "\n",
        "    # Upsampling\n",
        "\n",
        "    # output shape = (None, 16, 16d)\n",
        "    dense0 = Dense(16*c*d)(input_layer)\n",
        "    reshape0 = Reshape((c, c*d))(dense0)\n",
        "    relu0 = ReLU()(reshape0)\n",
        " \n",
        "    # output shape = (None, 64, 8d)\n",
        "    c //= 2\n",
        "    expanded0 = Lambda(lambda x: K.expand_dims(x, axis=1))(relu0)\n",
        "    conv0 = Conv2DTranspose(c*d, (1, 25), strides=(1, 4), padding='same')(expanded0)\n",
        "    slice0 = Lambda(lambda x: x[:, 0])(conv0)\n",
        "    relu1 = ReLU()(slice0)\n",
        "\n",
        "    # output shape = (None, 256, 4d)\n",
        "    c //= 2\n",
        "    expanded1 = Lambda(lambda x: K.expand_dims(x, axis=1))(relu1)\n",
        "    conv1 = Conv2DTranspose(c*d, (1, 25), strides=(1, 4), padding='same')(expanded1)\n",
        "    slice1 = Lambda(lambda x: x[:, 0])(conv1)\n",
        "    relu2 = ReLU()(slice1)\n",
        "\n",
        "    # output shape = (None, 1024, 2d)\n",
        "    c //= 2\n",
        "    expanded2 = Lambda(lambda x: K.expand_dims(x, axis=1))(relu2)\n",
        "    conv2 = Conv2DTranspose(c*d, (1, 25), strides=(1, 4), padding='same')(expanded2)\n",
        "    slice2 = Lambda(lambda x: x[:, 0])(conv2)\n",
        "    relu3 = ReLU()(slice2)\n",
        "\n",
        "    # output shape = (None, 4096, d)\n",
        "    c //= 2\n",
        "    expanded3 = Lambda(lambda x: K.expand_dims(x, axis=1))(relu3)\n",
        "    conv3 = Conv2DTranspose(c*d, (1, 25), strides=(1, 4), padding='same')(expanded3)\n",
        "    slice3 = Lambda(lambda x: x[:, 0])(conv3)\n",
        "    relu4 = ReLU()(slice3)\n",
        "\n",
        "    # output shape = (None, 16384, d)\n",
        "    expanded4 = Lambda(lambda x: K.expand_dims(x, axis=1))(relu4)\n",
        "    conv4 = Conv2DTranspose(c*d, (1, 25), strides=(1, 4), padding='same')(expanded4)\n",
        "    slice4 = Lambda(lambda x: x[:, 0])(conv4)\n",
        "    relu5 = ReLU()(slice4)\n",
        " \n",
        "\n",
        "    # output shape = (None, 65536, 1)\n",
        "    expanded5 = Lambda(lambda x: K.expand_dims(x, axis=1))(relu5)\n",
        "    conv5 = Conv2DTranspose(1, (1, 25), strides=(1, 4), padding='same')(expanded5)\n",
        "    slice5 = Lambda(lambda x: x[:, 0])(conv5)\n",
        "\n",
        "    #### num_samples == 65536\n",
        "\n",
        "    # Squeeze values between (-1, 1)\n",
        "    tanh0 = Activation('tanh')(slice5)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=tanh0)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "xCoTV55pTLsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation of PHase Shuffle\n",
        "def _apply_phaseshuffle(x, rad=2, pad_type='reflect'):\n",
        "    b, x_len, nch = x.get_shape().as_list()\n",
        "\n",
        "    phase = tf.random.uniform([], minval=-rad, maxval=rad + 1, dtype=tf.int32)\n",
        "    pad_l = tf.maximum(phase, 0)\n",
        "    pad_r = tf.maximum(-phase, 0)\n",
        "    phase_start = pad_r\n",
        "    x = tf.pad(x, [[0, 0], [pad_l, pad_r], [0, 0]], mode=pad_type)\n",
        "\n",
        "    x = x[:, phase_start:phase_start+x_len]\n",
        "    x.set_shape([b, x_len, nch])\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "tNxMKqw6qkdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator of the GAN\n",
        "def Critic(d, num_samples, c=1):\n",
        "\n",
        "    input = Input(shape=(num_samples, 1))\n",
        "\n",
        "    # Downsampling\n",
        "\n",
        "    # output shape = (None, 4096, d)\n",
        "    conv0 = Conv1D(c*d, 25, strides=4, padding='same')(input)\n",
        "    LReLU0 = LeakyReLU(alpha=0.2)(conv0)\n",
        "    phaseshuffle0 = Lambda(lambda x: _apply_phaseshuffle(x))(LReLU0)\n",
        "\n",
        "    # output shape = (None, 1024, 2d)\n",
        "    c *= 2\n",
        "    conv1 = Conv1D(c*d, 25, strides=4, padding='same')(phaseshuffle0)\n",
        "    LReLU1 = LeakyReLU(alpha=0.2)(conv1)\n",
        "    phaseshuffle1 = Lambda(lambda x: _apply_phaseshuffle(x))(LReLU1)\n",
        "\n",
        "    # output shape = (None, 256, 4d)\n",
        "    c *= 2\n",
        "    conv2 = Conv1D(c*d, 25, strides=4, padding='same')(phaseshuffle1)\n",
        "    LReLU2 = LeakyReLU(alpha=0.2)(conv2)\n",
        "    phaseshuffle2 = Lambda(lambda x: _apply_phaseshuffle(x))(LReLU2)\n",
        "\n",
        "    # output shape = (None, 64, 8d)\n",
        "    c *= 2\n",
        "    conv3 = Conv1D(c*d, 25, strides=4, padding='same')(phaseshuffle2)\n",
        "    LReLU3 = LeakyReLU(alpha=0.2)(conv3)\n",
        "    phaseshuffle3 = Lambda(lambda x: _apply_phaseshuffle(x))(LReLU3)\n",
        "\n",
        "    # output shape = (None, 16, 16d)\n",
        "    c *= 2\n",
        "    conv4 = Conv1D(c*d, 25, strides=4, padding='same')(phaseshuffle3)\n",
        "    LReLU4 = LeakyReLU(alpha=0.2)(conv4)\n",
        "\n",
        "    #### num_samples == 65536\n",
        "\n",
        "    # output shape = (None, 256d)\n",
        "    reshape0 = Reshape((64*c*d,))(LReLU4)#\n",
        "\n",
        "    # Output a critic score\n",
        "    dense1 = Dense(1)(reshape0)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=dense1)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "GVx_6cR0qaLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining hyperparameters of audio file\n",
        "\n",
        "MODEL_DIMS = 64   #Set the d values in Critic and generator\n",
        "NUM_SAMPLES = 65536 \n",
        "Fs = 16000  \n",
        "NOISE_LEN = 100\n",
        "\n",
        "# Defining Hyperparameters for Loss Function\n",
        "GRADIENT_PENALTY_WEIGHT = 10.0\n",
        "\n",
        "# Defining hyperparameters for training\n",
        "D_UPDATES_PER_G_UPDATE = 5 # Decides how many time a GAN will update the generator for a particular batch is used for training a \n",
        "EPOCHS = 50\n",
        "EPOCHS_PER_SAMPLE = 2  # To determing when to generate the audio file and save the model. It is generated at every even number of epochs\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/archive/Data/genres_original/blues\"\n",
        "INSTRUMENT = \"rock\"   # Change this according to the genre you want to develop\n",
        "\n",
        "\n",
        "# Creating directories\n",
        "\n",
        "paths = [\"/content/drive/MyDrive/Logs/train\", \n",
        "         f\"/content/drive/MyDrive/Model/{INSTRUMENT}/js\",\n",
        "         f\"/content/drive/MyDrive/Outputs/{INSTRUMENT}\",]\n",
        "\n",
        "for path in paths:\n",
        "    if not os.path.exists(os.path.join(os.getcwd(), path)):\n",
        "        os.makedirs(path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fojmg_R3YtsR",
        "outputId": "e1ac9982-7f6b-499a-c7d0-e87c6c8c0831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating necessary directories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class that contains GAN infrastructure\n",
        "\n",
        "class GAN:\n",
        "    def __init__(self, model_dims=MODEL_DIMS, num_samples=NUM_SAMPLES, \n",
        "                 gradient_penalty_weight=GRADIENT_PENALTY_WEIGHT, instrument=INSTRUMENT,\n",
        "                 noise_len=NOISE_LEN, batch_size=BATCH_SIZE, sr=Fs):\n",
        "        self.model_dims = model_dims\n",
        "        self.num_samples = num_samples\n",
        "        self.noise_dims = (noise_len,)\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        # self.G = GANModels.Generator(self.model_dims, num_samples)\n",
        "        self.G = Generator(self.model_dims, num_samples)\n",
        "        print(self.G.summary())\n",
        "\n",
        "        # self.D = GANModels.Critic(self.model_dims, num_samples)\n",
        "        self.D = Critic(self.model_dims, num_samples)\n",
        "        print(self.D.summary())\n",
        "        \n",
        "        self.G_optimizer = Adam(learning_rate=1e-4, beta_1=0.5, beta_2=0.9)\n",
        "        self.D_optimizer = Adam(learning_rate=1e-4, beta_1=0.5, beta_2=0.9)\n",
        "        \n",
        "        self.gradient_penalty_weight = gradient_penalty_weight\n",
        "        \n",
        "        self.sr = sr\n",
        "\n",
        "        self.instrument = INSTRUMENT\n",
        "\n",
        "    # Loss function for discriminator\n",
        "    def _d_loss_fn(self, rlog, flog):\n",
        "        fl = tf.reduce_mean(flog)\n",
        "        rl = - tf.reduce_mean(rlog)\n",
        "        return rl, fl\n",
        "    \n",
        "    # Loss function for generator\n",
        "    def _g_loss_fn(self, flog):\n",
        "        fl = - tf.reduce_meanflog)\n",
        "        return fl\n",
        "\n",
        "    # Calculates gradient penalty\n",
        "    def _gradient_penalty(self, real, fake):\n",
        "        # performs intrapolation\n",
        "        def _interpolate(a, b):\n",
        "            shape = [tf.shape(a)[0]] + [1] * (a.shape.ndims - 1)\n",
        "            alpha = tf.random.uniform(shape=shape, minval=0., maxval=1.)\n",
        "            inter = a + alpha * (b - a)\n",
        "            inter.set_shape(a.shape)\n",
        "            return inter\n",
        "            \n",
        "        x = _interpolate(real, fake)\n",
        "        with tf.GradientTape() as t:\n",
        "            t.watch(x)\n",
        "            pred = self.D(x, training=True)\n",
        "            \n",
        "        grad = t.gradient(pred, x)\n",
        "        norm = tf.norm(tf.reshape(grad, [tf.shape(grad)[0], -1]), axis=1)\n",
        "        gp = tf.reduce_mean((norm - 1.)**2)\n",
        "\n",
        "        return gp\n",
        "        \n",
        "    # Trains generator by keeping critic constant and returns the loss after traning\n",
        "    @tf.function\n",
        "    def train_G(self):\n",
        "        with tf.GradientTape() as t:\n",
        "            z = tf.random.normal(shape=(self.batch_size,) + self.noise_dims)\n",
        "            x_fake = self.G(z, training=True)\n",
        "            x_fake_d_logit = self.D(x_fake, training=True)\n",
        "            G_loss = self._g_loss_fn(x_fake_d_logit)\n",
        "\n",
        "        G_grad = t.gradient(G_loss, self.G.trainable_variables)\n",
        "        self.G_optimizer.apply_gradients(zip(G_grad, self.G.trainable_variables))\n",
        "\n",
        "        return {'g_loss': G_loss}\n",
        "\n",
        "    # Trains critic by keeping generator constant\n",
        "    @tf.function\n",
        "    def train_D(self, x_real):\n",
        "        with tf.GradientTape() as t:\n",
        "            z = tf.random.normal(shape=(x_real.shape[0],) + self.noise_dims)\n",
        "            x_fake = self.G(z, training=True)\n",
        "\n",
        "            x_real_d_logit = self.D(x_real, training=True)\n",
        "            x_fake_d_logit = self.D(x_fake, training=True)\n",
        "\n",
        "            x_real_d_loss, x_fake_d_loss = self._d_loss_fn(x_real_d_logit, x_fake_d_logit)\n",
        "            gp = self._gradient_penalty(x_real, x_fake)\n",
        "\n",
        "            D_loss = (x_real_d_loss + x_fake_d_loss) + gp * self.gradient_penalty_weight\n",
        "\n",
        "        D_grad = t.gradient(D_loss, self.D.trainable_variables)\n",
        "        self.D_optimizer.apply_gradients(zip(D_grad, self.D.trainable_variables))\n",
        "\n",
        "        return {'d_loss': x_real_d_loss + x_fake_d_loss, 'gp': gp}\n",
        "        \n",
        "    # Creates music samples and saves current generator model\n",
        "    def sample(self, epoch, num_samples=50):\n",
        "        self.G.save(f\"models/{epoch}.h5\")\n",
        "        z = tf.random.normal(shape=(num_samples,) + self.noise_dims)\n",
        "        result = self.G(z, training=False)\n",
        "        for i in range(num_samples):\n",
        "            audio = result[i, :, :]\n",
        "            audio = np.reshape(audio, (self.num_samples,))\n",
        "            sf.write(f\"/content/drive/MyDrive/Outputs/{self.instrument}/{epoch}-{i}.wav\",audio,samplerate=self.sr)\n",
        "\n"
      ],
      "metadata": {
        "id": "eV3qRR-pY9Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate model\n",
        "gan = GAN()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsPUaRGPibcX",
        "outputId": "794659cd-cfcb-478e-f806-2339f0c50c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16384)             1654784   \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 16, 1024)          0         \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 16, 1024)          0         \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 1, 16, 1024)       0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 1, 64, 512)       13107712  \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " lambda_1 (Lambda)           (None, 64, 512)           0         \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 64, 512)           0         \n",
            "                                                                 \n",
            " lambda_2 (Lambda)           (None, 1, 64, 512)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 1, 256, 256)      3277056   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " lambda_3 (Lambda)           (None, 256, 256)          0         \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 256, 256)          0         \n",
            "                                                                 \n",
            " lambda_4 (Lambda)           (None, 1, 256, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 1, 1024, 128)     819328    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " lambda_5 (Lambda)           (None, 1024, 128)         0         \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 1024, 128)         0         \n",
            "                                                                 \n",
            " lambda_6 (Lambda)           (None, 1, 1024, 128)      0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 1, 4096, 64)      204864    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " lambda_7 (Lambda)           (None, 4096, 64)          0         \n",
            "                                                                 \n",
            " re_lu_4 (ReLU)              (None, 4096, 64)          0         \n",
            "                                                                 \n",
            " lambda_8 (Lambda)           (None, 1, 4096, 64)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 1, 16384, 64)     102464    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " lambda_9 (Lambda)           (None, 16384, 64)         0         \n",
            "                                                                 \n",
            " re_lu_5 (ReLU)              (None, 16384, 64)         0         \n",
            "                                                                 \n",
            " lambda_10 (Lambda)          (None, 1, 16384, 64)      0         \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 1, 65536, 1)      1601      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " lambda_11 (Lambda)          (None, 65536, 1)          0         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 65536, 1)          0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,167,809\n",
            "Trainable params: 19,167,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 65536, 1)]        0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 16384, 64)         1664      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 16384, 64)         0         \n",
            "                                                                 \n",
            " lambda_12 (Lambda)          (None, 16384, 64)         0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 4096, 128)         204928    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 4096, 128)         0         \n",
            "                                                                 \n",
            " lambda_13 (Lambda)          (None, 4096, 128)         0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 1024, 256)         819456    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 1024, 256)         0         \n",
            "                                                                 \n",
            " lambda_14 (Lambda)          (None, 1024, 256)         0         \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 256, 512)          3277312   \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 256, 512)          0         \n",
            "                                                                 \n",
            " lambda_15 (Lambda)          (None, 256, 512)          0         \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 64, 1024)          13108224  \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 64, 1024)          0         \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 65536)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65537     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,477,121\n",
            "Trainable params: 17,477,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training data\n",
        "\n",
        "X_train = []\n",
        "for file in os.listdir(DATA_DIR): ### Modify for your data directory\n",
        "    with open(DATA_DIR + fr\"/{file}\", \"rb\") as f:\n",
        "        samples, _ = librosa.load(f, sr = Fs)\n",
        "        # Pad short audio files to NUM_SAMPLES duration\n",
        "        if len(samples) < NUM_SAMPLES:\n",
        "            audio = np.array([np.array([sample]) for sample in samples])\n",
        "            padding = np.zeros(shape=(NUM_SAMPLES - len(samples), 1), dtype='float32')\n",
        "            X_train.append(np.append(audio, padding, axis=0))\n",
        "        # Create slices of length NUM_SAMPLES from long audio\n",
        "        else:\n",
        "            p = len(samples) // (NUM_SAMPLES)\n",
        "            for i in range(p - 1):\n",
        "                sample = np.expand_dims(samples[i*NUM_SAMPLES:(i+1)*NUM_SAMPLES], axis=1)\n",
        "                X_train.append(sample)\n",
        "\n",
        "print(f\"X_train shape = {(len(X_train),) + X_train[0].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6wqZr3fbHJX",
        "outputId": "d5835b23-c1b3-416b-cfc2-bf1cd706a996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape = (600, 65536, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save some random training data slices and create baseline generated data for comparison\n",
        "for i in range(50):  \n",
        "    sf.write(f\"/content/drive/MyDrive/Outputs/{INSTRUMENT}/real-{i}.wav\", X_train[random.randint(0, len(X_train) - 1)],samplerate=Fs)\n"
      ],
      "metadata": {
        "id": "TBIvy5vFbtf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save some random data slices as fake for comparison\n",
        "gan.sample(\"fake\")\n",
        "train_summary_writer = tf.summary.create_file_writer(\"logs/train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhbY90nscVIp",
        "outputId": "877cb734-5b05-4deb-d98d-def6d8994078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFJdxvOUSEQd"
      },
      "outputs": [],
      "source": [
        "# Train GAN\n",
        "with train_summary_writer.as_default():\n",
        "    steps_per_epoch = len(X_train) // BATCH_SIZE \n",
        "\n",
        "    for e in range(EPOCHS):\n",
        "        for i in range(steps_per_epoch):\n",
        "            D_loss_sum = 0\n",
        "        \n",
        "            # Update dcritic a set number of times for each update of the generator\n",
        "            for n in range(D_UPDATES_PER_G_UPDATE):\n",
        "                gan.D.reset_states()\n",
        "                D_loss_dict = gan.train_D(np.array(random.sample(X_train, BATCH_SIZE)))\n",
        "                D_loss_sum += D_loss_dict['d_loss']\n",
        "            \n",
        "            # Calculate average loss of critic for current step\n",
        "            D_loss = D_loss_sum / D_UPDATES_PER_G_UPDATE\n",
        "            \n",
        "            G_loss_dict = gan.train_G()\n",
        "            G_loss = G_loss_dict['g_loss']\n",
        "        \n",
        "            # Write logs\n",
        "            tf.summary.scalar('d_loss', D_loss, step=(e*steps_per_epoch)+i)\n",
        "            tf.summary.scalar('g_loss', G_loss, step=(e*steps_per_epoch)+i)\n",
        "        \n",
        "            print(f\"step {(e*steps_per_epoch)+i}: d_loss = {D_loss} g_loss = {G_loss}\")\n",
        "        \n",
        "        # Periodically sample generator\n",
        "        if e % EPOCHS_PER_SAMPLE == 0:\n",
        "            gan.sample(e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vnjSBYuEIkTy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}